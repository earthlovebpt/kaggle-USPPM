{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6965d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:21.193607Z",
     "iopub.status.busy": "2023-08-16T12:02:21.193107Z",
     "iopub.status.idle": "2023-08-16T12:02:24.494124Z",
     "shell.execute_reply": "2023-08-16T12:02:24.493192Z"
    },
    "papermill": {
     "duration": 3.310371,
     "end_time": "2023-08-16T12:02:24.496398",
     "exception": false,
     "start_time": "2023-08-16T12:02:21.186027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import wandb\n",
    "user_secrets = UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5046f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:24.509109Z",
     "iopub.status.busy": "2023-08-16T12:02:24.507547Z",
     "iopub.status.idle": "2023-08-16T12:02:36.721250Z",
     "shell.execute_reply": "2023-08-16T12:02:36.720343Z"
    },
    "papermill": {
     "duration": 12.222102,
     "end_time": "2023-08-16T12:02:36.723676",
     "exception": false,
     "start_time": "2023-08-16T12:02:24.501574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from transformers import AutoTokenizer,TrainingArguments, Trainer, AutoModelForSequenceClassification,DataCollatorWithPadding, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93efe4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:36.735539Z",
     "iopub.status.busy": "2023-08-16T12:02:36.734934Z",
     "iopub.status.idle": "2023-08-16T12:02:36.741454Z",
     "shell.execute_reply": "2023-08-16T12:02:36.740571Z"
    },
    "papermill": {
     "duration": 0.014458,
     "end_time": "2023-08-16T12:02:36.743420",
     "exception": false,
     "start_time": "2023-08-16T12:02:36.728962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"name\":\"DeBERTa-LLRD\",\n",
    "    \"random_state\":123,\n",
    "    \"n_folds\":5,\n",
    "    \"model_path\":\"microsoft/deberta-v3-large\",\n",
    "    \"lr\":2e-5,\n",
    "    \"lr_decay\": 0.97,\n",
    "    \"weight_decay\":0.01,\n",
    "    \"n_epochs\":5,\n",
    "    \"batch_size\":18,\n",
    "    \"maxlen\": 100,\n",
    "    \"strategy\": \"GROUPKFOLD\",\n",
    "    \"loss_func\":\"MSELoss\",\n",
    "    \n",
    "}\n",
    "with open(\"config.json\", \"w\") as outfile:\n",
    "    json.dump(config, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552304ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:36.754713Z",
     "iopub.status.busy": "2023-08-16T12:02:36.754107Z",
     "iopub.status.idle": "2023-08-16T12:02:42.315942Z",
     "shell.execute_reply": "2023-08-16T12:02:42.314977Z"
    },
    "papermill": {
     "duration": 5.569927,
     "end_time": "2023-08-16T12:02:42.318230",
     "exception": false,
     "start_time": "2023-08-16T12:02:36.748303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9408452b8d4225b7ea0b412e73d793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb653a165b346a59d4ab9e15eadbcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9de42fded8498e928b735e19ecc9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config[\"model_path\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db91bf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:42.331846Z",
     "iopub.status.busy": "2023-08-16T12:02:42.331531Z",
     "iopub.status.idle": "2023-08-16T12:02:43.321073Z",
     "shell.execute_reply": "2023-08-16T12:02:43.320132Z"
    },
    "papermill": {
     "duration": 0.999277,
     "end_time": "2023-08-16T12:02:43.323660",
     "exception": false,
     "start_time": "2023-08-16T12:02:42.324383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abatement[SEP]abatement of pollution[SEP]FURNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abatement[SEP]act of abating[SEP]FURNITURE; DO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abatement[SEP]active catalyst[SEP]FURNITURE; D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abatement[SEP]eliminating process[SEP]FURNITUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abatement[SEP]forest region[SEP]FURNITURE; DOM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score code  \\\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  A47   \n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  A47   \n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25  A47   \n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  A47   \n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  A47   \n",
       "\n",
       "                                               title section  class subclass  \\\n",
       "0  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0      NaN   \n",
       "1  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0      NaN   \n",
       "2  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0      NaN   \n",
       "3  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0      NaN   \n",
       "4  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0      NaN   \n",
       "\n",
       "   group  main_group                                              input  \n",
       "0    NaN         NaN  abatement[SEP]abatement of pollution[SEP]FURNI...  \n",
       "1    NaN         NaN  abatement[SEP]act of abating[SEP]FURNITURE; DO...  \n",
       "2    NaN         NaN  abatement[SEP]active catalyst[SEP]FURNITURE; D...  \n",
       "3    NaN         NaN  abatement[SEP]eliminating process[SEP]FURNITUR...  \n",
       "4    NaN         NaN  abatement[SEP]forest region[SEP]FURNITURE; DOM...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\")\n",
    "titles_df = pd.read_csv(\"/kaggle/input/cpc-codes/titles.csv\")\n",
    "train_df = train_df.merge(titles_df, left_on='context', right_on='code')\n",
    "train_df['input'] = train_df[\"anchor\"] + \"[SEP]\" + train_df[\"target\"] + \"[SEP]\" + train_df['title']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22c4d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:43.337136Z",
     "iopub.status.busy": "2023-08-16T12:02:43.336849Z",
     "iopub.status.idle": "2023-08-16T12:02:46.720636Z",
     "shell.execute_reply": "2023-08-16T12:02:46.719496Z"
    },
    "papermill": {
     "duration": 3.392906,
     "end_time": "2023-08-16T12:02:46.722744",
     "exception": false,
     "start_time": "2023-08-16T12:02:43.329838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.188167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.580250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count  36473.000000\n",
       "mean      21.188167\n",
       "std       10.580250\n",
       "min        7.000000\n",
       "25%       13.000000\n",
       "50%       18.000000\n",
       "75%       26.000000\n",
       "max       92.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"len\"] = train_df[\"input\"].apply(lambda x: len(tokenizer(x)[\"input_ids\"]))\n",
    "train_df[[\"len\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f9176ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:46.737991Z",
     "iopub.status.busy": "2023-08-16T12:02:46.737681Z",
     "iopub.status.idle": "2023-08-16T12:02:47.176586Z",
     "shell.execute_reply": "2023-08-16T12:02:47.175610Z"
    },
    "papermill": {
     "duration": 0.448642,
     "end_time": "2023-08-16T12:02:47.179003",
     "exception": false,
     "start_time": "2023-08-16T12:02:46.730361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_folds(df, n_folds, strategy):\n",
    "    df[\"fold\"] = -1\n",
    "    # just use for spliting the data\n",
    "    df[\"bins\"] = pd.cut(\n",
    "        df[\"score\"], bins=5, labels=False\n",
    "    )\n",
    "    if strategy == \"KFOLD\":\n",
    "        kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config[\"random_state\"])\n",
    "        for i, (train , val) in enumerate(kf.split(X=df, y=df[\"bins\"].values)):\n",
    "            df.loc[val, 'fold'] = i\n",
    "            \n",
    "    elif strategy == \"GROUPKFOLD\":\n",
    "        gkf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=config[\"random_state\"])\n",
    "        for i, (train , val) in enumerate(gkf.split(X=df, y=df[\"bins\"].values, groups=df[\"anchor\"].values)):\n",
    "            df.loc[val, 'fold'] = i\n",
    "            \n",
    "    df = df.drop(\"bins\", axis=1)\n",
    "    return df\n",
    "\n",
    "train_df = create_folds(train_df, config[\"n_folds\"], config[\"strategy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d657ec53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:47.193158Z",
     "iopub.status.busy": "2023-08-16T12:02:47.192859Z",
     "iopub.status.idle": "2023-08-16T12:02:47.200268Z",
     "shell.execute_reply": "2023-08-16T12:02:47.199212Z"
    },
    "papermill": {
     "duration": 0.016619,
     "end_time": "2023-08-16T12:02:47.202158",
     "exception": false,
     "start_time": "2023-08-16T12:02:47.185539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.inputs = df['input'].values.astype(str)\n",
    "        self.targets = df['target'].values.astype(str)\n",
    "        self.label = df['score'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = self.inputs[item]\n",
    "        targets = self.targets[item]\n",
    "        label = self.label[item]\n",
    "        \n",
    "        return {\n",
    "        **tokenizer( \n",
    "            inputs,\n",
    "            max_length=config[\"maxlen\"],\n",
    "            padding=False,\n",
    "            truncation=True\n",
    "        ),\n",
    "        'label':label.astype(np.float32)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f71e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:47.216312Z",
     "iopub.status.busy": "2023-08-16T12:02:47.216019Z",
     "iopub.status.idle": "2023-08-16T12:02:47.228049Z",
     "shell.execute_reply": "2023-08-16T12:02:47.227208Z"
    },
    "papermill": {
     "duration": 0.021807,
     "end_time": "2023-08-16T12:02:47.230325",
     "exception": false,
     "start_time": "2023-08-16T12:02:47.208518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.reshape(len(predictions))\n",
    "    return {\n",
    "        'pearson': np.corrcoef(predictions, labels)[0][1]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_optimizer(model, config):\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    lr = config[\"lr\"]\n",
    "    # Linear layers\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"classifier\" in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": lr\n",
    "        }\n",
    "    ]\n",
    "    # Other layers\n",
    "    layers = [model.deberta.embeddings] + list(model.deberta.encoder.layer)\n",
    "    layers.reverse()\n",
    "    for layer in layers:\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": config[\"weight_decay\"],\n",
    "                \"lr\": lr\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": lr\n",
    "            }\n",
    "        ]\n",
    "        lr *= config[\"lr_decay\"]\n",
    "        \n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=config[\"lr\"])\n",
    "#     scheduler = get_linear_schedule_with_warmup(\n",
    "#         optimizer,\n",
    "#         num_warmup_steps=self.hparams.warmup_steps,\n",
    "#         num_training_steps=self.trainer.estimated_stepping_batches,\n",
    "#     )\n",
    "    return optimizer\n",
    "\n",
    "# def create_optimizer(model):\n",
    "#     no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "#     optimizer_parameters = [\n",
    "#         {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#         'lr': config[\"encoder_lr\"], 'weight_decay': config[\"weight_decay\"]},\n",
    "#         {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#         'lr': config[\"encoder_lr\"], 'weight_decay': 0.0},\n",
    "#         {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "#         'lr': config[\"decoder_lr\"], 'weight_decay': 0.0}\n",
    "#     ]\n",
    "#     scheduler = get_cosine_schedule_with_warmup(\n",
    "#             optimizer,\n",
    "#             num_training_steps=Config.epochs * len(train_dl),\n",
    "#             num_warmup_steps=50)\n",
    "#     return optimizer_parameters\n",
    "\n",
    "# class CorrLoss(nn.Module):\n",
    "#     \"\"\"\n",
    "#     use 1 - correlational coefficience between the output of the network and the target as the loss\n",
    "#     input (o, t):\n",
    "#         o: Variable of size (batch_size, 1) output of the network\n",
    "#         t: Variable of size (batch_size, 1) target value\n",
    "#     output (corr):\n",
    "#         corr: Variable of size (1)\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         super(CorrLoss, self).__init__()\n",
    "\n",
    "#     def forward(self, o, t):\n",
    "#         # calcu z-score for o and t\n",
    "#         o_m = o.mean(dim = 0)\n",
    "#         o_s = o.std(dim = 0)\n",
    "#         o_z = (o - o_m)/o_s\n",
    "\n",
    "#         t_m = t.mean(dim =0)\n",
    "#         t_s = t.std(dim = 0)\n",
    "#         t_z = (t - t_m)/t_s\n",
    "\n",
    "#         # calcu corr between o and t\n",
    "#         tmp = o_z * t_z\n",
    "#         corr = tmp.mean(dim = 0).squeeze(0)\n",
    "#         return  1 - corr\n",
    "\n",
    "# class CustomTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         labels = inputs.get(\"labels\")\n",
    "#         # forward pass\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs.get(\"logits\")\n",
    "#         # compute custom loss\n",
    "#         if config[\"loss_func\"] == \"MSELoss\":\n",
    "#             loss_fct = nn.MSELoss()\n",
    "#         elif config[\"loss_func\"] == \"CorrLoss\":\n",
    "#             loss_fct = CorrLoss()\n",
    "        \n",
    "#         loss = loss_fct(logits, labels.unsqueeze(-1))\n",
    "#         return (loss, outputs) if return_outputs else loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbeaa2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T12:02:47.244333Z",
     "iopub.status.busy": "2023-08-16T12:02:47.243547Z",
     "iopub.status.idle": "2023-08-16T17:34:30.066711Z",
     "shell.execute_reply": "2023-08-16T17:34:30.065815Z"
    },
    "papermill": {
     "duration": 19902.832255,
     "end_time": "2023-08-16T17:34:30.068717",
     "exception": false,
     "start_time": "2023-08-16T12:02:47.236462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnorrawee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230816_120247-2t1och1i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeBERTa-LLRD_fold0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/2t1och1i\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98995536e9a84d6b91f023c8ed493233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8005' max='8005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8005/8005 1:04:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.024867</td>\n",
       "      <td>0.813518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.816110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.021580</td>\n",
       "      <td>0.824111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.022879</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.022547</td>\n",
       "      <td>0.820092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▅▁▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson ▁▃█▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▅▂█▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▄▇▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▄▇▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.02255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson 0.82009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 36.1201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 212.209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 11.794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      loss_func MSELoss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay 0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     model_path microsoft/deberta-v3...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           name DeBERTa-LLRD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state 123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       strategy GROUPKFOLD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 8005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.1970323771340588e+16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.01481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3842.0038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 37.491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeBERTa-LLRD_fold0\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/2t1och1i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230816_120247-2t1och1i/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230816_130846-0k8l56kn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeBERTa-LLRD_fold1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/0k8l56kn\u001b[0m\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8205' max='8205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8205/8205 1:05:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>0.821652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.823877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.827923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.023366</td>\n",
       "      <td>0.828014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>0.827412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▃▁▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson ▁▃██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▃▁█▁▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▆█▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▆█▁█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▃▃▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.02295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson 0.82741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 33.5792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 206.765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 11.495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      loss_func MSELoss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay 0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     model_path microsoft/deberta-v3...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           name DeBERTa-LLRD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state 123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       strategy GROUPKFOLD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 8205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.2153871184589468e+16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.0153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3904.1244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 37.819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeBERTa-LLRD_fold1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/0k8l56kn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230816_130846-0k8l56kn/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230816_141518-luyiqc85\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeBERTa-LLRD_fold2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/luyiqc85\u001b[0m\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8015' max='8015' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8015/8015 1:04:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.021464</td>\n",
       "      <td>0.831439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.022316</td>\n",
       "      <td>0.832357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.841406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.021134</td>\n",
       "      <td>0.839186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.838485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▄█▁▃▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson ▁▂█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▃▆▂▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▆▃▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▆▃▇█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.02188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson 0.83848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 36.0862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 211.466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 11.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      loss_func MSELoss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay 0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     model_path microsoft/deberta-v3...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           name DeBERTa-LLRD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state 123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       strategy GROUPKFOLD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 8015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.1929333214553948e+16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.01569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3840.9585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 37.545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeBERTa-LLRD_fold2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/luyiqc85\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230816_141518-luyiqc85/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230816_152051-j8y7r8pm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeBERTa-LLRD_fold3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/j8y7r8pm\u001b[0m\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8205' max='8205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8205/8205 1:05:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.025410</td>\n",
       "      <td>0.805036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.023650</td>\n",
       "      <td>0.817107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.816376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.023151</td>\n",
       "      <td>0.821295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.023620</td>\n",
       "      <td>0.819938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▃▃▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson ▁▆▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▄▁▄█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▅█▅▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▅█▅▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.02362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson 0.81994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 33.1724\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 209.331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 11.636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      loss_func MSELoss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay 0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     model_path microsoft/deberta-v3...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           name DeBERTa-LLRD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state 123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       strategy GROUPKFOLD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 8205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.2230105975437374e+16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3916.9142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 37.694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeBERTa-LLRD_fold3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/j8y7r8pm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230816_152051-j8y7r8pm/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230816_162735-jerbljlj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeBERTa-LLRD_fold4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/jerbljlj\u001b[0m\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8110' max='8110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8110/8110 1:05:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>0.809842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.821780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.825416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.824459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.825089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▁▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson ▁▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▃▁▅█▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▆█▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▆█▄▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     batch_size 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.02237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/pearson 0.82509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 34.861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 209.116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 11.618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      loss_func MSELoss\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                             lr 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       lr_decay 0.97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         maxlen 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     model_path microsoft/deberta-v3...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       n_epochs 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        n_folds 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                           name DeBERTa-LLRD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   random_state 123\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                       strategy GROUPKFOLD\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 8110\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.2279713286035202e+16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.01652\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3925.9297\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 37.167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 2.066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   weight_decay 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeBERTa-LLRD_fold4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/norrawee/USPPPM/runs/jerbljlj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230816_162735-jerbljlj/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "oof_df = pd.DataFrame()\n",
    "for fold in range(config[\"n_folds\"]):\n",
    "    wandb.init(project=\"USPPPM\", name=f\"{config['name']}_fold{fold}\")\n",
    "    wandb.log(config)\n",
    "    \n",
    "    tr_data = train_df[train_df['fold']!=fold].reset_index(drop=True)\n",
    "    va_data = train_df[train_df['fold']==fold].reset_index(drop=True)\n",
    "    tr_dataset = TrainDataset(tr_data)\n",
    "    va_dataset = TrainDataset(va_data)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"/tmp/uspppm\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=config[\"batch_size\"],\n",
    "        per_device_eval_batch_size=config[\"batch_size\"],\n",
    "        num_train_epochs=config[\"n_epochs\"],\n",
    "        metric_for_best_model=\"pearson\",\n",
    "        load_best_model_at_end=True,\n",
    "        learning_rate=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(config[\"model_path\"], num_labels=1)\n",
    "    optimizer = create_optimizer(model, config)\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=tr_dataset,\n",
    "        eval_dataset=va_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "        optimizers=(optimizer,None)\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    shutil.rmtree(f\"/tmp/uspppm\")\n",
    "    trainer.save_model(f\"uspppm_{fold}\")\n",
    "    \n",
    "    outputs = trainer.predict(va_dataset)\n",
    "    predictions = outputs.predictions.reshape(-1)\n",
    "    va_data['preds'] = predictions\n",
    "    oof_df = pd.concat([oof_df, va_data])\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9682a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:34:30.100329Z",
     "iopub.status.busy": "2023-08-16T17:34:30.100043Z",
     "iopub.status.idle": "2023-08-16T17:34:30.109903Z",
     "shell.execute_reply": "2023-08-16T17:34:30.108891Z"
    },
    "papermill": {
     "duration": 0.027584,
     "end_time": "2023-08-16T17:34:30.111819",
     "exception": false,
     "start_time": "2023-08-16T17:34:30.084235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson': 0.8255098776481588}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = oof_df['preds'].values\n",
    "label = oof_df['score'].values\n",
    "eval_pred = predictions, label\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3fc7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T17:34:30.143770Z",
     "iopub.status.busy": "2023-08-16T17:34:30.142978Z",
     "iopub.status.idle": "2023-08-16T17:34:30.790934Z",
     "shell.execute_reply": "2023-08-16T17:34:30.789955Z"
    },
    "papermill": {
     "duration": 0.666737,
     "end_time": "2023-08-16T17:34:30.793566",
     "exception": false,
     "start_time": "2023-08-16T17:34:30.126829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_df.to_csv('oof_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b124592",
   "metadata": {
    "papermill": {
     "duration": 0.015096,
     "end_time": "2023-08-16T17:34:30.824103",
     "exception": false,
     "start_time": "2023-08-16T17:34:30.809007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7e8a2",
   "metadata": {
    "papermill": {
     "duration": 0.014649,
     "end_time": "2023-08-16T17:34:30.853813",
     "exception": false,
     "start_time": "2023-08-16T17:34:30.839164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2562a",
   "metadata": {
    "papermill": {
     "duration": 0.014853,
     "end_time": "2023-08-16T17:34:30.883702",
     "exception": false,
     "start_time": "2023-08-16T17:34:30.868849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19943.060974,
   "end_time": "2023-08-16T17:34:33.863551",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-16T12:02:10.802577",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00427d487c704a7e994b745bb650c75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "044b2de3fe1244b0a7e202fe1c02679a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a826d8559bd43e5ab6e9d3f17a82d27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b2c7fed780e43739e8e06fafbf4515c",
       "placeholder": "​",
       "style": "IPY_MODEL_00427d487c704a7e994b745bb650c75a",
       "value": "Downloading pytorch_model.bin: 100%"
      }
     },
     "1b2c7fed780e43739e8e06fafbf4515c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1cbf8db005874e86a041738421f388e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ce5505370284e9fb4df1c4dba598a8c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "24156ebb88324549acde66e84190fc2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28ef2ccca38e4cc18ccbf0b92ea0b9b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "290b7db7b6d743c0ad159d2c428abcde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_28ef2ccca38e4cc18ccbf0b92ea0b9b1",
       "placeholder": "​",
       "style": "IPY_MODEL_a57d27db2476484c9ccf15e3dc8e733a",
       "value": "Downloading (…)lve/main/config.json: 100%"
      }
     },
     "3479196bbfb04d2c8da28b430ddf6e69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "381b8a05d47e41818569144048a918b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4227a4cbf68845d3b6577e75a12728de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4b75bf76d7544b639fe52f6ca4f97236": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_381b8a05d47e41818569144048a918b0",
       "placeholder": "​",
       "style": "IPY_MODEL_044b2de3fe1244b0a7e202fe1c02679a",
       "value": " 52.0/52.0 [00:00&lt;00:00, 3.37kB/s]"
      }
     },
     "5839022d41ea4894a7bb65cbbe005e85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fcaf2d86401342ceae74ff483b147747",
       "max": 873673253.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d9679ff8d30a43bcb9ca18096550aa69",
       "value": 873673253.0
      }
     },
     "675ab7b8980d42ef955ae7413ab7526f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f8a5ac219d44858806c4bfff601e970": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "70a706338c61436c9a9cd731cc435549": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a117c27707aa4e63ae0b89f94063e038",
       "max": 580.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ee91041fbd7c4afda24bfd77ce7d7844",
       "value": 580.0
      }
     },
     "70c3096173e744d885961daca5e2c235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "786e639f19f14d889efb967c340c12db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79655013cf9543389b50d1863b50977b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ced6a68e9e124c14832fa5d0e86f0038",
       "placeholder": "​",
       "style": "IPY_MODEL_675ab7b8980d42ef955ae7413ab7526f",
       "value": "Downloading spm.model: 100%"
      }
     },
     "7e9936e9d3b647edafa1bfd2b3c71787": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4e1e88da1af4060a183446c55034d78",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4227a4cbf68845d3b6577e75a12728de",
       "value": 2464616.0
      }
     },
     "88943fa24f4b479eb4b1a0e07eb814ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8fc2efbf44c2424d99e6e261d4adbaf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a07929205bfb4eea81c41a05ae192d20",
       "placeholder": "​",
       "style": "IPY_MODEL_6f8a5ac219d44858806c4bfff601e970",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 3.96MB/s]"
      }
     },
     "98995536e9a84d6b91f023c8ed493233": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a826d8559bd43e5ab6e9d3f17a82d27",
        "IPY_MODEL_5839022d41ea4894a7bb65cbbe005e85",
        "IPY_MODEL_b80c4934e51d4d6998d1e303309fe683"
       ],
       "layout": "IPY_MODEL_a7c86a74f1214410a69b182422dccb15"
      }
     },
     "9a9408452b8d4225b7ea0b412e73d793": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b825b7899651406086f9add2be3720eb",
        "IPY_MODEL_ac32b0f37c2741ccaa159fd86d3b1104",
        "IPY_MODEL_4b75bf76d7544b639fe52f6ca4f97236"
       ],
       "layout": "IPY_MODEL_dfe20cbd9aa94b639bef6a3e0dcb7e6d"
      }
     },
     "a07929205bfb4eea81c41a05ae192d20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a117c27707aa4e63ae0b89f94063e038": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a12dea8d7fdb4859ab9aed5f8db8cdf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a57d27db2476484c9ccf15e3dc8e733a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a7c86a74f1214410a69b182422dccb15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac32b0f37c2741ccaa159fd86d3b1104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3479196bbfb04d2c8da28b430ddf6e69",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d7f23d1ef86743b591f42bc32abc347c",
       "value": 52.0
      }
     },
     "b80c4934e51d4d6998d1e303309fe683": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1cbf8db005874e86a041738421f388e4",
       "placeholder": "​",
       "style": "IPY_MODEL_a12dea8d7fdb4859ab9aed5f8db8cdf8",
       "value": " 874M/874M [00:27&lt;00:00, 31.5MB/s]"
      }
     },
     "b825b7899651406086f9add2be3720eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_70c3096173e744d885961daca5e2c235",
       "placeholder": "​",
       "style": "IPY_MODEL_1ce5505370284e9fb4df1c4dba598a8c",
       "value": "Downloading (…)okenizer_config.json: 100%"
      }
     },
     "bc026a3bb57e40a989dbef2956d682b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bf9de42fded8498e928b735e19ecc9cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_79655013cf9543389b50d1863b50977b",
        "IPY_MODEL_7e9936e9d3b647edafa1bfd2b3c71787",
        "IPY_MODEL_8fc2efbf44c2424d99e6e261d4adbaf2"
       ],
       "layout": "IPY_MODEL_88943fa24f4b479eb4b1a0e07eb814ef"
      }
     },
     "ced6a68e9e124c14832fa5d0e86f0038": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6a8383070b54bf28b6f5b222211f9cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_786e639f19f14d889efb967c340c12db",
       "placeholder": "​",
       "style": "IPY_MODEL_bc026a3bb57e40a989dbef2956d682b9",
       "value": " 580/580 [00:00&lt;00:00, 31.6kB/s]"
      }
     },
     "d7f23d1ef86743b591f42bc32abc347c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d9679ff8d30a43bcb9ca18096550aa69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dfe20cbd9aa94b639bef6a3e0dcb7e6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "edb653a165b346a59d4ab9e15eadbcf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_290b7db7b6d743c0ad159d2c428abcde",
        "IPY_MODEL_70a706338c61436c9a9cd731cc435549",
        "IPY_MODEL_d6a8383070b54bf28b6f5b222211f9cc"
       ],
       "layout": "IPY_MODEL_24156ebb88324549acde66e84190fc2b"
      }
     },
     "ee91041fbd7c4afda24bfd77ce7d7844": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f4e1e88da1af4060a183446c55034d78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcaf2d86401342ceae74ff483b147747": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
